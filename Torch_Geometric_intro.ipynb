{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpyE37mkr4u+BfuHWaAS/X",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhu2690/PyTorchNotes/blob/main/Torch_Geometric_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Torch-Geometric(or PyG)?\n",
        "Graphs are everywhere‚Äîthink social networks (nodes are people, edges are friendships), molecular structures (nodes are atoms, edges are bonds), or citation networks (nodes are papers, edges are citations). Torch-Geometric([doc](https://pytorch-geometric.readthedocs.io/en/latest/)) makes it easy to apply deep learning techniques to these structures.\n",
        "\n",
        "For this introduction, we‚Äôll focus on node classification, where the goal is to predict a label for each node in a graph (e.g., classifying people into communities in a social network)."
      ],
      "metadata": {
        "id": "ps9Pe5z8AMIm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can install the torch-geometric library from PyPI using pip."
      ],
      "metadata": {
        "id": "0TpOATpt_4rx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-9JCfNK_umt",
        "outputId": "5350d676-ebff-4fcf-ab1d-8706b637d981"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-geometric in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.11.15)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2025.3.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (3.2.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->torch-geometric) (1.18.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch-geometric) (3.0.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torch-geometric) (2025.1.31)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-geometric"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is a Graph?\n",
        "\n",
        "A graph is a fundamental data structure used to model relationships between objects. It consists of two primary components:\n",
        "\n",
        "**Nodes (Vertices):**\n",
        "\n",
        "* These represent the entities within the graph. Think of them as the individual items or points of interest.\n",
        "\n",
        "**Edges:**\n",
        "\n",
        "* These represent the connections or relationships between the nodes. They indicate how the entities are linked.\n",
        "\n",
        "Nodes can have features (e.g., a person‚Äôs age or interests).\n",
        "\n",
        "Edges can have features or weights (e.g., the strength of a friendship).\n",
        "\n",
        "We often have labels for nodes (e.g., which community a person belongs to)."
      ],
      "metadata": {
        "id": "d_vqdDeoAtZ-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Torch-Geometric represents graphs using a Data object, which we‚Äôll explore next."
      ],
      "metadata": {
        "id": "7hbjXJ68BkTV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The Data Object in Torch-Geometric\n",
        "\n",
        "The `Data` object is the core of Torch-Geometric. It‚Äôs a container that holds all the information about a graph."
      ],
      "metadata": {
        "id": "qxjn_EhaCc4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "\n",
        "# Define edges: a triangle (0-1, 1-2, 2-0)\n",
        "edge_index = torch.tensor([[0, 1, 1, 2, 2, 0],\n",
        "                           [1, 0, 2, 1, 0, 2]], dtype=torch.long)\n",
        "\n",
        "# Node features: each node has a 2D feature vector\n",
        "x = torch.tensor([[1.0, 0.0], [0.0, 1.0], [1.0, 1.0]], dtype=torch.float)\n",
        "\n",
        "# Node labels: binary classification (0 or 1)\n",
        "y = torch.tensor([0, 1, 0], dtype=torch.float)\n",
        "\n",
        "# Create the Data object\n",
        "data = Data(x=x, edge_index=edge_index, y=y)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hRWmvXVPAG2F",
        "outputId": "0badc3fc-1a7a-4a60-c0e2-506fa3b2954d"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[3, 2], edge_index=[2, 6], y=[3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.x"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OB-c9nIwC3dW",
        "outputId": "10f8bc4d-7cfe-4214-c813-9dd24947d554"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [0., 1.],\n",
              "        [1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.edge_index"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZpm-wmPC7a6",
        "outputId": "241b735b-7ccd-4401-e816-e8c5343a7950"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 1, 1, 2, 2, 0],\n",
              "        [1, 0, 2, 1, 0, 2]])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `edge_index`: Defines the graph structure; edges are undirected, so we include both directions (e.g., 0‚Üí1 and 1‚Üí0).\n",
        "* `x`: Gives each node a feature vector (here, 2D for simplicity).\n",
        "* `y`: Assigns a label to each node."
      ],
      "metadata": {
        "id": "99vUzRKiALOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using NetworkX with Torch-Geometric\n",
        "\n",
        "NetworkX is a Python library for creating and manipulating graphs. Torch-Geometric provides a utility, `from_networkx`, to convert a NetworkX graph into a `Data` object. This is super useful for building custom graphs."
      ],
      "metadata": {
        "id": "bfUiWuQZDlE7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q networkx"
      ],
      "metadata": {
        "id": "l8N-t6xDDsrG"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# Create a simple graph with NetworkX (avoiding the Karate Club graph)\n",
        "G = nx.Graph()\n",
        "G.add_edges_from([(0, 1), (0, 2), (1, 2), (2, 3)])\n",
        "\n",
        "# Optionally, you can add node features to your NetworkX graph\n",
        "for i in G.nodes():\n",
        "    G.nodes[i]['x'] = [1.0, 0.0]  # Example: Every node gets the same 2-dimensional feature\n",
        "\n",
        "# Convert NetworkX graph to a Torch-Geometric Data object\n",
        "data = from_networkx(G)\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HV3lAWqZDK_H",
        "outputId": "84b3434b-4f4b-410d-dddf-77280846c4aa"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[4, 2], edge_index=[2, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "NetworkX‚Äôs `draw` function lets you visualize the graph."
      ],
      "metadata": {
        "id": "psC9dRY7E9pU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(4,4))\n",
        "nx.draw(G, with_labels=True)\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436
        },
        "id": "ZX2U1WLPD-de",
        "outputId": "db61aed5-6428-4f45-cb23-17475ca9af13"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building a GNN Model Using PyG\n",
        "\n",
        "GNNs use specialized layers to process graph-structured data. One of the basic layers is `GCNConv` from PyTorch Geometric, which is based on the graph convolutional network (GCN) model.\n",
        "\n",
        "#### Example: A Single GCN Layer"
      ],
      "metadata": {
        "id": "m6QmXUOfHHwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GCNConv\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# Create a GCN layer: converting 2 input features to 4 output features.\n",
        "conv = GCNConv(in_channels=2, out_channels=4)\n",
        "\n",
        "# A forward pass through the layer.\n",
        "# Create dummy edge weights (optional; if not provided, defaults will be used)\n",
        "edge_weight = torch.ones(data.edge_index.size(1))\n",
        "\n",
        "# Pass the data through the layer\n",
        "x_out = conv(data.x, data.edge_index, edge_weight)\n",
        "print(\"GCN Layer Output:\\n\", x_out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2MpRRMuEAY_",
        "outputId": "72cc2769-9850-400b-bc33-ec1bdc6a6b9d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GCN Layer Output:\n",
            " tensor([[ 0.7449, -0.4942, -0.3893,  0.6769],\n",
            "        [ 0.7449, -0.4942, -0.3893,  0.6769],\n",
            "        [ 0.9208, -0.6108, -0.4813,  0.8368],\n",
            "        [ 0.6655, -0.4415, -0.3479,  0.6048]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exploring More GNN Layers\n",
        "\n",
        "Torch-Geometric comes with various GNN layers. Here are a few additional options:\n",
        "\n",
        "* **GraphSAGE (`SAGEConv`):** Aggregates neighbor information by sampling and pooling.\n",
        "* **GATConv:** Uses an attention mechanism on edges.\n",
        "* **GraphConv:** Another variation on graph convolutions."
      ],
      "metadata": {
        "id": "cYn9luYzIBKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import SAGEConv, GATConv, GraphConv\n",
        "\n",
        "# Define layers converting from 2 input features to 4 output features.\n",
        "sage_layer = SAGEConv(in_channels=2, out_channels=4)\n",
        "gat_layer = GATConv(in_channels=2, out_channels=4, heads=2, concat=False)\n",
        "graphconv_layer = GraphConv(in_channels=2, out_channels=4)\n",
        "\n",
        "print(\"SAGE Layer Output:\\n\", sage_layer(data.x, data.edge_index))\n",
        "print(\"GAT Layer Output:\\n\", gat_layer(data.x, data.edge_index))\n",
        "print(\"GraphConv Layer Output:\\n\", graphconv_layer(data.x, data.edge_index))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOTvKCPyHvW-",
        "outputId": "dfd15aa5-02d3-48d2-bcdd-2fe3aa5e42db"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SAGE Layer Output:\n",
            " tensor([[ 0.8496,  1.1451,  0.2273, -0.2608],\n",
            "        [ 0.8496,  1.1451,  0.2273, -0.2608],\n",
            "        [ 0.8496,  1.1451,  0.2273, -0.2608],\n",
            "        [ 0.8496,  1.1451,  0.2273, -0.2608]], grad_fn=<AddBackward0>)\n",
            "GAT Layer Output:\n",
            " tensor([[-0.2080,  0.1580,  0.3182,  0.5768],\n",
            "        [-0.2080,  0.1580,  0.3182,  0.5768],\n",
            "        [-0.2080,  0.1580,  0.3182,  0.5768],\n",
            "        [-0.2080,  0.1580,  0.3182,  0.5768]], grad_fn=<AddBackward0>)\n",
            "GraphConv Layer Output:\n",
            " tensor([[ 1.8585, -0.4158,  1.3489, -0.1955],\n",
            "        [ 1.8585, -0.4158,  1.3489, -0.1955],\n",
            "        [ 2.3305, -0.4159,  1.7207, -0.5071],\n",
            "        [ 1.3865, -0.4157,  0.9771,  0.1161]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each layer processes the graph slightly differently. Experimenting with these layers is an excellent way to understand how different architectures affect performance."
      ],
      "metadata": {
        "id": "4YcxzUq-IKWU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Incorporating Normalization: GraphNorm\n",
        "\n",
        "Normalization layers like `GraphNorm` can help stabilize training by normalizing the features across nodes for each graph."
      ],
      "metadata": {
        "id": "GgPSwCjRIP8d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.nn import GraphNorm\n",
        "\n",
        "# Define a GraphNorm layer for 4-dimensional features.\n",
        "gnorm = GraphNorm(in_channels=4)\n",
        "\n",
        "# Apply GCN convolution first and then normalization.\n",
        "x_gcn = conv(data.x, data.edge_index, edge_weight=None)\n",
        "x_norm = gnorm(x_gcn)\n",
        "print(\"After GraphNorm:\\n\", x_norm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_mDU7HUIAAI",
        "outputId": "3cab350e-b557-4294-940b-816839b07fa3"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After GraphNorm:\n",
            " tensor([[-0.2581,  0.2580,  0.2578, -0.2581],\n",
            "        [-0.2581,  0.2580,  0.2578, -0.2581],\n",
            "        [ 1.6236, -1.6224, -1.6211,  1.6234],\n",
            "        [-1.1073,  1.1065,  1.1056, -1.1072]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Working with Multiple Graphs Using DataLoader\n",
        "\n",
        "When you have many graphs (e.g., different molecules or social network subgraphs), you can use PyG‚Äôs `DataLoader` to handle batch processing. This is analogous to PyTorch‚Äôs `DataLoader` but specialized for graphs.\n",
        "\n",
        "#### Example: Creating a Mini-Batch of Graphs"
      ],
      "metadata": {
        "id": "UA8DxqRiIyoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch_geometric.data import Data\n",
        "from torch_geometric.loader import DataLoader\n",
        "\n",
        "# Create a list of 5 simple graph Data objects (for demonstration purposes, we use the same graph repeatedly)\n",
        "graph_list = []\n",
        "for _ in range(5):\n",
        "    graph = Data(x=data.x, edge_index=data.edge_index, y=data.y)\n",
        "    graph_list.append(graph)\n",
        "\n",
        "# Create a DataLoader for batching\n",
        "loader = DataLoader(graph_list, batch_size=2)\n",
        "\n",
        "# Iterate over mini-batches\n",
        "for batch in loader:\n",
        "    print(\"Batch x shape:\", batch.x.shape)             # Combined node features from batch graphs\n",
        "    print(\"Batch edge_index shape:\", batch.edge_index.shape)\n",
        "    print(\"Batch vector:\", batch.batch)                  # Indicates which node belongs to which graph\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T1pLVFfGIhvd",
        "outputId": "645a77b2-08a9-4cd3-f438-812aa30e7300"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch x shape: torch.Size([8, 2])\n",
            "Batch edge_index shape: torch.Size([2, 16])\n",
            "Batch vector: tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch x shape: torch.Size([8, 2])\n",
            "Batch edge_index shape: torch.Size([2, 16])\n",
            "Batch vector: tensor([0, 0, 0, 0, 1, 1, 1, 1])\n",
            "Batch x shape: torch.Size([4, 2])\n",
            "Batch edge_index shape: torch.Size([2, 8])\n",
            "Batch vector: tensor([0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What If the Nodes Don‚Äôt Have Any Features?\n",
        "Not all graphs come with node features. For example, many social or citation networks might only give you the graph structure‚Äîwho connects to whom‚Äîbut no additional data about the nodes. So what do we do?\n",
        "\n",
        "ü§î Torch-Geometric (and GNNs in general) require node features to start the message-passing. If your nodes don‚Äôt have any features, one common trick is to use one-hot encodings based on the node index. This gives each node a unique identity."
      ],
      "metadata": {
        "id": "9TUY_L45NmMJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "\n",
        "# Create a graph with 4 nodes and some edges\n",
        "edge_index = torch.tensor([\n",
        "    [0, 1, 2, 3, 0, 2],\n",
        "    [1, 0, 3, 2, 2, 0]\n",
        "], dtype=torch.long)\n",
        "\n",
        "# No node features!\n",
        "# x = None or torch.empty(num_nodes, 0) will both fail in GCNConv\n",
        "\n",
        "num_nodes = 4\n",
        "# Let's try to use a dummy model\n",
        "conv = GCNConv(in_channels=4, out_channels=2)\n",
        "\n",
        "# Try 1: No node features (just pass None) ‚Äì will raise an error!\n",
        "try:\n",
        "    x_none = None\n",
        "    data = Data(x=x_none, edge_index=edge_index)\n",
        "    out = conv(data.x, data.edge_index)\n",
        "except Exception as e:\n",
        "    print(\"‚ùå Failed without node features:\", e)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEM5FQQKNse1",
        "outputId": "858b0ecc-4c25-4373-babd-d45b47af4c6c"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùå Failed without node features: 'NoneType' object has no attribute 'size'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fix: Use One-Hot Encoding for Node Indices\n"
      ],
      "metadata": {
        "id": "LTmcbY2FN3Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use one-hot encoding for node IDs\n",
        "x_onehot = torch.eye(num_nodes)\n",
        "\n",
        "data = Data(x=x_onehot, edge_index=edge_index)\n",
        "out = conv(data.x, data.edge_index)\n",
        "\n",
        "print(\"‚úÖ Output with one-hot features:\\n\", out)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZL7y767GN10Z",
        "outputId": "28b33b1d-ede7-4294-d2d0-990e5e400420"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Output with one-hot features:\n",
            " tensor([[-0.8042, -0.2406],\n",
            "        [-0.6951,  0.0365],\n",
            "        [-0.7411, -0.4766],\n",
            "        [-0.5817, -0.6396]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Simple Training Loop for Node Classification\n",
        "\n",
        "Let‚Äôs put together a small GNN model and demonstrate training for a node classification task. We‚Äôll use train and validation masks to focus on subsets of nodes for training and evaluation.\n",
        "\n",
        "#### Example: Defining the Model and Training Loop"
      ],
      "metadata": {
        "id": "zysyEbiYJYyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "from torch_geometric.data import Data\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.utils import from_networkx\n",
        "\n",
        "# Step 1: Create a simple graph (star graph with 5 nodes)\n",
        "G = nx.star_graph(4)  # Central node 0, connected to 1, 2, 3, 4\n",
        "data = from_networkx(G)\n",
        "\n",
        "# Step 2: Add node features and labels\n",
        "data.x = torch.ones(data.num_nodes, 2)  # 2D feature vector [1, 1] for each node\n",
        "data.y = torch.tensor([0, 1, 1, 1, 1], dtype=torch.float)  # Central node: 0, others: 1\n",
        "\n",
        "# Step 3: Create train and validation masks\n",
        "num_nodes = data.num_nodes\n",
        "indices = np.random.permutation(num_nodes)\n",
        "train_idx, val_idx = indices[:2], indices[2:]  # 2 nodes for train, 3 for val\n",
        "data.train_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "data.val_mask = torch.zeros(num_nodes, dtype=torch.bool)\n",
        "data.train_mask[train_idx] = True\n",
        "data.val_mask[val_idx] = True\n",
        "\n",
        "# Step 4: Define the GCN model\n",
        "class SimpleGCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleGCN, self).__init__()\n",
        "        self.conv1 = GCNConv(in_channels=2, out_channels=16)  # Input: 2D features (why 2D? because our node has 2 input features)\n",
        "        self.conv2 = GCNConv(in_channels=16, out_channels=8)\n",
        "        self.linear= nn.Linear(in_features=8, out_features=1) # Output: 1D logits (why 1D? because we are going to pass it into a sigmoid function, which requires a single output value per node for binary classification)\n",
        "\n",
        "    def forward(self, data):\n",
        "        x, edge_index = data.x, data.edge_index\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x, edge_index)\n",
        "        x = self.linear(x)\n",
        "        return x  # Raw logits\n",
        "\n",
        "# Step 5: Initialize model, optimizer, and loss\n",
        "model = SimpleGCN()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "# Step 6: Training function\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    logits = model(data)  # Shape: [num_nodes, 1]\n",
        "    # Compute loss only on training nodes\n",
        "    loss = criterion(logits[data.train_mask], data.y[data.train_mask].unsqueeze(1))\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()\n",
        "\n",
        "# Step 7: Training loop\n",
        "for epoch in range(1, 101):\n",
        "    loss = train()\n",
        "    if epoch % 20 == 0:\n",
        "        print(f'Epoch {epoch}, Loss: {loss:.4f}')\n",
        "\n",
        "# Step 8: Evaluation function\n",
        "def evaluate(mask):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        logits = model(data)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        pred = (probs > 0.5).float()\n",
        "        correct = (pred[mask] == data.y[mask].unsqueeze(1)).sum().item()\n",
        "        acc = correct / mask.sum().item()\n",
        "    return acc\n",
        "\n",
        "# Step 9: Evaluate on validation set\n",
        "val_acc = evaluate(data.val_mask)\n",
        "print(f'Validation Accuracy: {val_acc:.4f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HxDRsEYvI8E7",
        "outputId": "4a1ea444-084f-4fd5-c29c-ebcbe5f538f9"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20, Loss: 0.4606\n",
            "Epoch 40, Loss: 0.3810\n",
            "Epoch 60, Loss: 0.3043\n",
            "Epoch 80, Loss: 0.2329\n",
            "Epoch 100, Loss: 0.1712\n",
            "Validation Accuracy: 0.6667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see here, we use a mask to split the graph‚Äôs nodes into training, validation, and test sets, ensuring the model learns from some nodes and is evaluated on others for generalization. Without a mask, the model trains and evaluates on all nodes, risking overfitting and providing no measure of performance on unseen data."
      ],
      "metadata": {
        "id": "2N0OLr00KlmZ"
      }
    }
  ]
}