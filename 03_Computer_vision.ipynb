{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOIs0BOuRoVnUlWT97BpuLH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sidhu2690/CogniXis/blob/main/03_Computer_vision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "84grOByLk0Ro"
      },
      "outputs": [],
      "source": [
        "!wget -q https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip -O pizza_steak_sushi.zip\n",
        "!unzip -q pizza_steak_sushi.zip -d ./data/"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = \"/content/data/train\"\n",
        "test_dir = \"/content/data/test\""
      ],
      "metadata": {
        "id": "pGNP6MoVlEMM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "YMpoDUIJlPtk"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transforms = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std= [0.5, 0.5, 0.5])\n",
        "])"
      ],
      "metadata": {
        "id": "2bB6_1O3lH4c"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data=datasets.ImageFolder(root=train_dir, transform= data_transforms)\n",
        "test_data= datasets.ImageFolder(root=test_dir, transform= data_transforms)"
      ],
      "metadata": {
        "id": "CjMKKw7RlKHk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader=DataLoader(train_data, batch_size=32, shuffle= True)\n",
        "test_loader= DataLoader(test_data, batch_size=32, shuffle= True)"
      ],
      "metadata": {
        "id": "Am-fGyj4lNK6"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device= \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "q749awrSlnrk"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN_Model(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.model= nn.Sequential(\n",
        "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride= 1, padding=1),  #32, 224, 224\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),                                                     # 32, 112, 112\n",
        "\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1),  # 64, 112, 112\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),                                                     # 64, 56, 56\n",
        "\n",
        "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride= 1, padding=1),# 128, 56, 56\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),                                                    # 128, 28, 28\n",
        "\n",
        "        nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1),# 256, 28, 28\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2),                                                      # 256, 14, 14\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(256* 14*14, 256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Dropout(0.2),\n",
        "        nn.Linear(512, 3)\n",
        "\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.model(x)\n",
        "\n",
        "Model= CNN_Model().to(device)"
      ],
      "metadata": {
        "id": "1N_MgyXslu0D"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn= nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.SGD(params=Model.parameters(),\n",
        "                          lr=0.01)"
      ],
      "metadata": {
        "id": "sszYkQ9UoHOA"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def training_loop(model, train_loader, test_loader, optimizer, loss_fn, epochs):\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        train_loss, train_correct=0,0\n",
        "\n",
        "        for X,y in train_loader:\n",
        "            X,y= X.to(device), y.to(device)\n",
        "\n",
        "            y_pred=model(X)\n",
        "            loss=loss_fn(y_pred, y)\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_correct+= (y_pred.argmax(1) == y).sum().item()\n",
        "\n",
        "        train_accuracy=train_correct / len(train_loader.dataset) * 100\n",
        "\n",
        "        # evaluation\n",
        "\n",
        "        model.eval()\n",
        "\n",
        "        test_loss, test_correct= 0, 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for X,y in test_loader:\n",
        "                X, y= X.to(device), y.to(device)\n",
        "\n",
        "                test_pred= model(X)\n",
        "                loss=loss_fn(test_pred, y)\n",
        "                test_loss+= loss.item()\n",
        "\n",
        "                test_correct+= (test_pred.argmax(1) == y).sum().item()\n",
        "            test_accuracy= test_correct / len(test_loader.dataset) * 100\n",
        "\n",
        "            print(f\"Epochs: {epoch} | train loss: {train_loss} | train accuracy: {train_accuracy} | test loss: {test_loss} | test accurcy: {test_accuracy}\" )\n",
        "\n",
        "training_loop(Model, train_loader, test_loader, optimizer, loss_fn, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJ1-QzhCoeit",
        "outputId": "39fd60c4-f3f2-4f27-9c61-5d092883aa7f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 0 | train loss: 8.787685871124268 | train accuracy: 32.0 | test loss: 3.287534236907959 | test accurcy: 41.333333333333336\n",
            "Epochs: 1 | train loss: 8.813910245895386 | train accuracy: 32.0 | test loss: 3.294824957847595 | test accurcy: 41.333333333333336\n",
            "Epochs: 2 | train loss: 8.785962343215942 | train accuracy: 33.77777777777778 | test loss: 3.301422357559204 | test accurcy: 25.333333333333336\n",
            "Epochs: 3 | train loss: 8.801839828491211 | train accuracy: 35.11111111111111 | test loss: 3.300467610359192 | test accurcy: 25.333333333333336\n",
            "Epochs: 4 | train loss: 8.78228211402893 | train accuracy: 35.55555555555556 | test loss: 3.2997387647628784 | test accurcy: 36.0\n",
            "Epochs: 5 | train loss: 8.763275861740112 | train accuracy: 41.333333333333336 | test loss: 3.2996386289596558 | test accurcy: 33.33333333333333\n",
            "Epochs: 6 | train loss: 8.809857964515686 | train accuracy: 35.11111111111111 | test loss: 3.2897286415100098 | test accurcy: 33.33333333333333\n",
            "Epochs: 7 | train loss: 8.779077291488647 | train accuracy: 34.66666666666667 | test loss: 3.2833826541900635 | test accurcy: 32.0\n",
            "Epochs: 8 | train loss: 8.804493308067322 | train accuracy: 33.33333333333333 | test loss: 3.2950522899627686 | test accurcy: 40.0\n",
            "Epochs: 9 | train loss: 8.783085227012634 | train accuracy: 35.55555555555556 | test loss: 3.306843400001526 | test accurcy: 25.333333333333336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VCX9_bCJphnb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}